{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb4adcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse_Subpixel_Convolution module initialized!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import Sparse_Subpixel_Convolution as SpConv\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from ipywidgets import Layout, interact, IntSlider, FloatSlider\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "#Consts\n",
    "nanometers_per_pixel = 46\n",
    "\n",
    "dt = 0.1\n",
    "t_max = 6.4\n",
    "\n",
    "psf_peak_pixel_size = 32\n",
    "\n",
    "camera_fov_px = 64\n",
    "\n",
    "steps = int(t_max / dt)\n",
    "\n",
    "exD = 5000.0\n",
    "exParticle_count = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ca5b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample width:  960\n"
     ]
    }
   ],
   "source": [
    "#Load PSF\n",
    "PSF_subpx = np.load(\"../PSF_subpx_fl64.npy\")\n",
    "sample_size_px = PSF_subpx.shape[2] - camera_fov_px\n",
    "print(\"Sample width: \", sample_size_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d993413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FOV_edge = sample_size_px / 2 - camera_fov_px / 2\n",
    "\n",
    "sample_count = 100\n",
    "\n",
    "PSF_subpx_fl64 = PSF_subpx.astype('float64')\n",
    "PSF_subpx_fl32 = PSF_subpx.astype('float32')\n",
    "\n",
    "PSF_subpx_ui32 = (PSF_subpx * 65535.0).astype('uint32')\n",
    "PSF_subpx_ui16 = (PSF_subpx * 255.0).astype('uint16')\n",
    "    \n",
    "def GenParticlePositions(D : float, particle_count : int, step_count : int, loop : bool):\n",
    "    variance = 4 * D * dt / (nanometers_per_pixel ** 2)\n",
    "\n",
    "    start_poss = np.random.uniform(0, sample_size_px, (particle_count, 2))\n",
    "    dposs = np.random.normal(0, variance, (step_count, particle_count, 2))\n",
    "\n",
    "    poss = start_poss[None, :, :] + np.cumsum(dposs, axis = 0)\n",
    "    \n",
    "    s = sample_size_px\n",
    "    \n",
    "    if(loop):\n",
    "        poss[poss < 0] = poss[poss < 0] + np.floor(-poss[poss < 0] / s + 1) * s\n",
    "        poss[poss > s] = poss[poss > s] - np.floor( poss[poss > s] / s + 0) * s\n",
    "    \n",
    "    poss -= FOV_edge\n",
    "    \n",
    "    return poss #shape: (steps, particle_count, coordinates)\n",
    "\n",
    "sz = camera_fov_px\n",
    "subpixels = PSF_subpx.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "number_of_threads = multiprocessing.cpu_count()\n",
    "print(number_of_threads)\n",
    "\n",
    "threads_begin = 1\n",
    "threads_end = number_of_threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54320233",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle generation done in 0.06511330604553223 s\n",
      "Datatype: fl64\n",
      "\t Threads: 1--- Convolutions done in 3.5821213722229004 s\n",
      "\t Threads: 2--- Convolutions done in 2.3477227687835693 s\n",
      "\t Threads: 3--- Convolutions done in 2.176400899887085 s\n",
      "\t Threads: 4--- Convolutions done in 1.8783209323883057 s\n",
      "\t Threads: 5--- Convolutions done in 2.2047104835510254 s\n",
      "\t Threads: 6--- Convolutions done in 1.742337942123413 s\n",
      "\t Threads: 7--- Convolutions done in 2.0656607151031494 s\n",
      "\t Threads: 8--- Convolutions done in 1.6692938804626465 s\n",
      "\t Threads: 9--- Convolutions done in 2.166684865951538 s\n",
      "\t Threads: 10--- Convolutions done in 1.6732327938079834 s\n",
      "\t Threads: 11--- Convolutions done in 2.27363657951355 s\n",
      "\t Threads: 12--- Convolutions done in 1.6608963012695312 s\n",
      "\t Threads: 13--- Convolutions done in 2.1912081241607666 s\n",
      "\t Threads: 14--- Convolutions done in 1.8183438777923584 s\n",
      "\t Threads: 15--- Convolutions done in 1.5899100303649902 s\n",
      "\t Threads: 16--- Convolutions done in 2.0797810554504395 s\n",
      "\t Threads: 17--- Convolutions done in 1.579033613204956 s\n",
      "\t Threads: 18--- Convolutions done in 2.1486663818359375 s\n",
      "\t Threads: 19--- Convolutions done in 1.8166165351867676 s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatatype: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m str_types[d])\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(threads_begin, threads_end):\n\u001b[0;32m---> 47\u001b[0m     samples, perfs_omp[d, i\u001b[38;5;241m-\u001b[39mthreads_begin] \u001b[38;5;241m=\u001b[39m \u001b[43mtest_convolution_parallel_omp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparticle_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatypes\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Threads: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Convolutions done in \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(perfs_omp[d, i\u001b[38;5;241m-\u001b[39mthreads_begin]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m sampless\u001b[38;5;241m.\u001b[39mappend(samples)\n",
      "Cell \u001b[0;32mIn[4], line 30\u001b[0m, in \u001b[0;36mtest_convolution_parallel_omp\u001b[0;34m(thread_count, particle_positions, step_count, particle_count, datatyp)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datatyp \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39muint16:\n\u001b[1;32m     28\u001b[0m     psf \u001b[38;5;241m=\u001b[39m PSF_subpx_ui16        \n\u001b[0;32m---> 30\u001b[0m samples \u001b[38;5;241m=\u001b[39m \u001b[43mSpConv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera_fov_px\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_sizes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintensities\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m perf \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m startTime\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [samples, perf]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Benchmark\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "particle_count = exParticle_count * sample_count\n",
    "\n",
    "poss = GenParticlePositions(exD, particle_count, steps, True)\n",
    "sample_sizes = np.full((sample_count), exParticle_count, dtype=np.int32)\n",
    "\n",
    "print(\"Particle generation done in \" + str(time.time() - startTime) + \" s\")\n",
    "\n",
    "\n",
    "#Convolution\n",
    "\n",
    "def test_convolution_parallel_omp(thread_count, particle_positions, step_count, particle_count, datatyp):    \n",
    "    intensities = np.full((particle_count), 1, dtype=datatyp)\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    psf = PSF_subpx    \n",
    "    if datatyp == np.float64:\n",
    "        psf = PSF_subpx_fl64\n",
    "    if datatyp == np.float32:\n",
    "        psf = PSF_subpx_fl32\n",
    "    if datatyp == np.uint32:\n",
    "        psf = PSF_subpx_ui32\n",
    "    if datatyp == np.uint16:\n",
    "        psf = PSF_subpx_ui16        \n",
    "\n",
    "    samples = SpConv.convolve(thread_count, camera_fov_px, poss, sample_sizes, intensities, psf, datatyp, verbose=0)\n",
    "    \n",
    "    perf = time.time() - startTime\n",
    "    return [samples, perf]\n",
    "\n",
    "\n",
    "#Testing\n",
    "\n",
    "datatypes = [np.float64, np.float32, np.uint32, np.uint16]\n",
    "str_types = [\"fl64\", \"fl32\", \"ui32\", \"ui16\"]\n",
    "perfs_omp = np.zeros((len(datatypes), threads_end - threads_begin))\n",
    "\n",
    "sampless = list()\n",
    "\n",
    "for d in range(len(datatypes)):\n",
    "    print(\"Datatype: \" + str_types[d])\n",
    "    for i in range(threads_begin, threads_end):\n",
    "        samples, perfs_omp[d, i-threads_begin] = test_convolution_parallel_omp(i, poss, steps, particle_count, datatypes[d])\n",
    "        print(\"\\t Threads: \" + str(i) + \"--- Convolutions done in \" + str(perfs_omp[d, i-threads_begin]) + \" s\")\n",
    "    sampless.append(samples)\n",
    "\n",
    "    plt.plot(perfs_omp[d])\n",
    "plt.legend(str_types)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de221d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c2ac4ce19bb4943afe2572323283587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='step', layout=Layout(width='100%'), max=63), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Draw Fast\n",
    "sample_inds = np.insert(np.cumsum(sample_sizes), 0, 0)\n",
    "\n",
    "def plot_step_fast(step, sample_cur):\n",
    "    \n",
    "    begin = sample_inds[sample_cur]\n",
    "    end = begin + sample_sizes[sample_cur]\n",
    "    \n",
    "    x = poss[step, begin:end, 1]\n",
    "    y = poss[step, begin:end, 0]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis([-FOV_edge, sample_size_px-FOV_edge, -FOV_edge, sample_size_px-FOV_edge])\n",
    "    plt.gca().add_patch(Rectangle((0, 0), camera_fov_px, camera_fov_px, edgecolor = 'red', fill=False))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.scatter(x,y)\n",
    "    \n",
    "    imgs = sampless[1][sample_cur]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(imgs[step, :, :])\n",
    "    plt.axis([-0.5, camera_fov_px-0.5, -0.5, camera_fov_px-0.5])\n",
    "    plt.scatter(x,y, c=\"red\")\n",
    "    plt.title(str_types[1])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "interact(plot_step_fast, step=IntSlider(min=0, max=steps - 1, layout=Layout(width='100%')), sample_cur=IntSlider(min=0, max=sample_count - 1, layout=Layout(width='100%')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efa1047a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001ddf84090410a8c14ca0e128153d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='step', layout=Layout(width='100%'), max=63), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Draw Fast & Generate targets\n",
    "sample_inds = np.insert(np.cumsum(sample_sizes), 0, 0)\n",
    "\n",
    "xc_in_sight = (poss[:, :, 0] > 0) & (poss[:, :, 0] < camera_fov_px)\n",
    "yc_in_sight = (poss[:, :, 1] > 0) & (poss[:, :, 1] < camera_fov_px)\n",
    "pt_in_sight = xc_in_sight & yc_in_sight\n",
    "\n",
    "particles_in_sight_cnt = list()\n",
    "for i in range(sample_count):\n",
    "    particles_in_sight_cnt.append(np.sum(pt_in_sight[:, sample_inds[i]:sample_inds[i+1]], axis = 1))\n",
    "\n",
    "precision_multiplier = 4\n",
    "targets = np.zeros((steps, sample_count, camera_fov_px * precision_multiplier, camera_fov_px * precision_multiplier), dtype=np.uint8)\n",
    "\n",
    "for i in range(sample_count):\n",
    "    for step in range(steps):\n",
    "        sample_pt = np.nonzero(pt_in_sight[step, sample_inds[i]:sample_inds[i+1]])\n",
    "        sample_ps = poss[step, sample_inds[i]:sample_inds[i+1], :]\n",
    "        positions_in_sight = (sample_ps[sample_pt, :] * precision_multiplier).astype(int)[0]\n",
    "        targets[step, i, positions_in_sight[:, 0], positions_in_sight[:, 1]] = 1\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def plot_step_fast_wTargets(step, sample_cur):\n",
    "    \n",
    "    begin = sample_inds[sample_cur]\n",
    "    end = begin + sample_sizes[sample_cur]\n",
    "    \n",
    "    x = poss[step, begin:end, 1]\n",
    "    y = poss[step, begin:end, 0]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis([-FOV_edge, sample_size_px-FOV_edge, -FOV_edge, sample_size_px-FOV_edge])\n",
    "    plt.gca().add_patch(Rectangle((0, 0), camera_fov_px, camera_fov_px, edgecolor = 'red', fill=False))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.scatter(x,y)\n",
    "    \n",
    "    imgs = sampless[1][sample_cur]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(imgs[step, :, :])\n",
    "    plt.axis([-0.5, camera_fov_px-0.5, -0.5, camera_fov_px-0.5])\n",
    "    plt.scatter(x,y, c=\"red\")\n",
    "    plt.title(str_types[1])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(targets[step, sample_cur, :, :])\n",
    "    plt.axis([-0.5, camera_fov_px * precision_multiplier-0.5, -0.5, camera_fov_px * precision_multiplier-0.5])\n",
    "    plt.show()\n",
    "    print(particles_in_sight_cnt[sample_cur][step])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "interact(plot_step_fast_wTargets, step=IntSlider(min=0, max=steps - 1, layout=Layout(width='100%')), sample_cur=IntSlider(min=0, max=sample_count - 1, layout=Layout(width='100%')));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3d0f00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bde695df65043d880ff558f14179834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='step', layout=Layout(width='100%'), max=63), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Draw All\n",
    "sample_inds = np.insert(np.cumsum(sample_sizes), 0, 0)\n",
    "\n",
    "def plot_step(step, sample_cur):\n",
    "    \n",
    "    begin = sample_inds[sample_cur]\n",
    "    end = begin + sample_sizes[sample_cur]\n",
    "    \n",
    "    x = poss[step, begin:end, 1]\n",
    "    y = poss[step, begin:end, 0]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.axis([-FOV_edge, sample_size_px-FOV_edge, -FOV_edge, sample_size_px-FOV_edge])\n",
    "    plt.gca().add_patch(Rectangle((0, 0), camera_fov_px, camera_fov_px, edgecolor = 'red', fill=False))\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()\n",
    "    \n",
    "    for d in range(len(str_types)):\n",
    "        imgs = sampless[d][sample_cur]\n",
    "        plt.subplot(1, 2, d%2 + 1)\n",
    "        plt.imshow(imgs[step, :, :])\n",
    "        plt.axis([-0.5, camera_fov_px-0.5, -0.5, camera_fov_px-0.5])\n",
    "        plt.scatter(x,y, c=\"red\")\n",
    "        plt.title(str_types[d])\n",
    "        \n",
    "        if (d + 1) % 2 == 0:\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "interact(plot_step, step=IntSlider(min=0, max=steps - 1, layout=Layout(width='100%')), sample_cur=IntSlider(min=0, max=sample_count - 1, layout=Layout(width='100%')));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0f69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
