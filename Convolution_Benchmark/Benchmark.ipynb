{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4adcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#imports\n",
    "\n",
    "import numpy as np\n",
    "import Sparse_Subpixel_Convolution as SpConv\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "from ipywidgets import Layout, interact, IntSlider, FloatSlider\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "#Consts\n",
    "nanometers_per_pixel = 46\n",
    "\n",
    "dt = 0.1\n",
    "t_max = 6.4\n",
    "\n",
    "psf_peak_pixel_size = 32\n",
    "\n",
    "camera_fov_px = 64\n",
    "\n",
    "steps = int(t_max / dt)\n",
    "\n",
    "exD = 5000.0\n",
    "exParticle_count = 1000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75ca5b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample width:  448\n"
     ]
    }
   ],
   "source": [
    "#Load PSF\n",
    "PSF_subpx = np.load(\"../PSF_subpx_fl64.npy\")\n",
    "sample_size_px = PSF_subpx.shape[2] - camera_fov_px\n",
    "print(\"Sample width: \", sample_size_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d993413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "FOV_edge = sample_size_px / 2 - camera_fov_px / 2\n",
    "\n",
    "sample_count = 2048\n",
    "\n",
    "PSF_subpx_fl64 = PSF_subpx.astype('float64')\n",
    "PSF_subpx_fl32 = PSF_subpx.astype('float32')\n",
    "\n",
    "PSF_subpx_ui32 = (PSF_subpx * 65535.0).astype('uint32')\n",
    "PSF_subpx_ui16 = (PSF_subpx * 255.0).astype('uint16')\n",
    "    \n",
    "def GenParticlePositions(D : float, particle_count : int, step_count : int, loop : bool):\n",
    "    variance = 4 * D * dt / (nanometers_per_pixel ** 2)\n",
    "\n",
    "    start_poss = np.random.uniform(0, sample_size_px, (particle_count, 2))\n",
    "    dposs = np.random.normal(0, variance, (step_count, particle_count, 2))\n",
    "\n",
    "    poss = start_poss[None, :, :] + np.cumsum(dposs, axis = 0)\n",
    "    \n",
    "    s = sample_size_px\n",
    "    \n",
    "    if(loop):\n",
    "        poss[poss < 0] = poss[poss < 0] + np.floor(-poss[poss < 0] / s + 1) * s\n",
    "        poss[poss > s] = poss[poss > s] - np.floor( poss[poss > s] / s + 0) * s\n",
    "    \n",
    "    poss -= FOV_edge\n",
    "    \n",
    "    return poss #shape: (steps, particle_count, coordinates)\n",
    "\n",
    "sz = camera_fov_px\n",
    "subpixels = PSF_subpx.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "number_of_threads = multiprocessing.cpu_count()\n",
    "print(number_of_threads)\n",
    "\n",
    "threads_begin = 1\n",
    "threads_end = number_of_threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0716b920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Subpixel Convolution initialized\n",
      "Preparation of memory took 0 ms\n"
     ]
    }
   ],
   "source": [
    "optimized_thread_cnt = 1\n",
    "conv_calc = SpConv.ConvolutionCalculator_fl32(PSF_subpx_fl32, optimized_thread_cnt, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54320233",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Particle generation done in 10.118466138839722 s\n",
      "Datatype: fl32\n",
      "\n",
      "OMP max threads: 11\n",
      "OMP setting number of threads to 1\n",
      "\t Threads: 1--- Convolutions done in 82.1813313961029 s\n",
      "Computation of convolutions took 77547 ms\n"
     ]
    }
   ],
   "source": [
    "#Benchmark\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "particle_count = exParticle_count * sample_count\n",
    "\n",
    "poss = GenParticlePositions(exD, particle_count, steps, True)\n",
    "sample_sizes = np.full((sample_count), exParticle_count, dtype=np.int32)\n",
    "\n",
    "print(\"Particle generation done in \" + str(time.time() - startTime) + \" s\")\n",
    "\n",
    "\n",
    "#Convolution\n",
    "\n",
    "def test_convolution_parallel_omp(thread_count, particle_positions, step_count, particle_count, datatyp):    \n",
    "    intensities = np.full((particle_count), 1, dtype=datatyp)\n",
    "\n",
    "    startTime = time.time()\n",
    "    \n",
    "    psf = PSF_subpx    \n",
    "    if datatyp == np.float64:\n",
    "        psf = PSF_subpx_fl64\n",
    "    if datatyp == np.float32:\n",
    "        psf = PSF_subpx_fl32\n",
    "    if datatyp == np.uint32:\n",
    "        psf = PSF_subpx_ui32\n",
    "    if datatyp == np.uint16:\n",
    "        psf = PSF_subpx_ui16        \n",
    "\n",
    "    samples = conv_calc.convolve(thread_count, camera_fov_px, poss, sample_sizes, intensities, verbose=1)\n",
    "    \n",
    "#     conv_calc.async_convolve(thread_count, camera_fov_px, poss, sample_sizes, intensities, verbose=1)\n",
    "# #     samples = conv_calc.async_convolve_join(verbose=1)\n",
    "#     time.sleep(45)\n",
    "#     samples = 0\n",
    "    \n",
    "    perf = time.time() - startTime\n",
    "    return [samples, perf]\n",
    "\n",
    "\n",
    "#Testing\n",
    "\n",
    "# datatypes = [np.float64, np.float32, np.uint32, np.uint16]\n",
    "# str_types = [\"fl64\", \"fl32\", \"ui32\", \"ui16\"]\n",
    "datatypes = [np.float32]\n",
    "str_types = [\"fl32\"]\n",
    "perfs_omp = np.zeros((len(datatypes), threads_end - threads_begin))\n",
    "\n",
    "sampless = list()\n",
    "\n",
    "for d in range(len(datatypes)):\n",
    "    print(\"Datatype: \" + str_types[d])\n",
    "    for i in range(threads_begin, threads_end):\n",
    "        samples, perfs_omp[d, i-threads_begin] = test_convolution_parallel_omp(i, poss, steps, particle_count, datatypes[d])\n",
    "        print(\"\\t Threads: \" + str(i) + \"--- Convolutions done in \" + str(perfs_omp[d, i-threads_begin]) + \" s\")\n",
    "    sampless.append(samples)\n",
    "\n",
    "    plt.plot(perfs_omp[d])\n",
    "plt.legend(str_types)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de221d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576f73ed28974b67b2d14467fdf38746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='step', layout=Layout(width='100%'), max=63), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Draw Fast\n",
    "sample_inds = np.insert(np.cumsum(sample_sizes), 0, 0)\n",
    "\n",
    "def plot_step_fast(step, sample_cur):\n",
    "    \n",
    "    begin = sample_inds[sample_cur]\n",
    "    end = begin + sample_sizes[sample_cur]\n",
    "    \n",
    "    x = poss[step, begin:end, 1]\n",
    "    y = poss[step, begin:end, 0]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis([-FOV_edge, sample_size_px-FOV_edge, -FOV_edge, sample_size_px-FOV_edge])\n",
    "    plt.gca().add_patch(Rectangle((0, 0), camera_fov_px, camera_fov_px, edgecolor = 'red', fill=False))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.scatter(x,y)\n",
    "    \n",
    "    imgs = sampless[0][sample_cur]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(imgs[step, :, :])\n",
    "    plt.axis([-0.5, camera_fov_px-0.5, -0.5, camera_fov_px-0.5])\n",
    "    plt.scatter(x,y, c=\"red\")\n",
    "    plt.title(str_types[0])\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "interact(plot_step_fast, step=IntSlider(min=0, max=steps - 1, layout=Layout(width='100%')), sample_cur=IntSlider(min=0, max=sample_count - 1, layout=Layout(width='100%')));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "efa1047a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a001ddf84090410a8c14ca0e128153d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='step', layout=Layout(width='100%'), max=63), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Draw Fast & Generate targets\n",
    "sample_inds = np.insert(np.cumsum(sample_sizes), 0, 0)\n",
    "\n",
    "xc_in_sight = (poss[:, :, 0] > 0) & (poss[:, :, 0] < camera_fov_px)\n",
    "yc_in_sight = (poss[:, :, 1] > 0) & (poss[:, :, 1] < camera_fov_px)\n",
    "pt_in_sight = xc_in_sight & yc_in_sight\n",
    "\n",
    "particles_in_sight_cnt = list()\n",
    "for i in range(sample_count):\n",
    "    particles_in_sight_cnt.append(np.sum(pt_in_sight[:, sample_inds[i]:sample_inds[i+1]], axis = 1))\n",
    "\n",
    "precision_multiplier = 4\n",
    "targets = np.zeros((steps, sample_count, camera_fov_px * precision_multiplier, camera_fov_px * precision_multiplier), dtype=np.uint8)\n",
    "\n",
    "for i in range(sample_count):\n",
    "    for step in range(steps):\n",
    "        sample_pt = np.nonzero(pt_in_sight[step, sample_inds[i]:sample_inds[i+1]])\n",
    "        sample_ps = poss[step, sample_inds[i]:sample_inds[i+1], :]\n",
    "        positions_in_sight = (sample_ps[sample_pt, :] * precision_multiplier).astype(int)[0]\n",
    "        targets[step, i, positions_in_sight[:, 0], positions_in_sight[:, 1]] = 1\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def plot_step_fast_wTargets(step, sample_cur):\n",
    "    \n",
    "    begin = sample_inds[sample_cur]\n",
    "    end = begin + sample_sizes[sample_cur]\n",
    "    \n",
    "    x = poss[step, begin:end, 1]\n",
    "    y = poss[step, begin:end, 0]\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.axis([-FOV_edge, sample_size_px-FOV_edge, -FOV_edge, sample_size_px-FOV_edge])\n",
    "    plt.gca().add_patch(Rectangle((0, 0), camera_fov_px, camera_fov_px, edgecolor = 'red', fill=False))\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.scatter(x,y)\n",
    "    \n",
    "    imgs = sampless[1][sample_cur]\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(imgs[step, :, :])\n",
    "    plt.axis([-0.5, camera_fov_px-0.5, -0.5, camera_fov_px-0.5])\n",
    "    plt.scatter(x,y, c=\"red\")\n",
    "    plt.title(str_types[1])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(targets[step, sample_cur, :, :])\n",
    "    plt.axis([-0.5, camera_fov_px * precision_multiplier-0.5, -0.5, camera_fov_px * precision_multiplier-0.5])\n",
    "    plt.show()\n",
    "    print(particles_in_sight_cnt[sample_cur][step])\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "interact(plot_step_fast_wTargets, step=IntSlider(min=0, max=steps - 1, layout=Layout(width='100%')), sample_cur=IntSlider(min=0, max=sample_count - 1, layout=Layout(width='100%')));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3d0f00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bde695df65043d880ff558f14179834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='step', layout=Layout(width='100%'), max=63), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#Draw All\n",
    "sample_inds = np.insert(np.cumsum(sample_sizes), 0, 0)\n",
    "\n",
    "def plot_step(step, sample_cur):\n",
    "    \n",
    "    begin = sample_inds[sample_cur]\n",
    "    end = begin + sample_sizes[sample_cur]\n",
    "    \n",
    "    x = poss[step, begin:end, 1]\n",
    "    y = poss[step, begin:end, 0]\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.axis([-FOV_edge, sample_size_px-FOV_edge, -FOV_edge, sample_size_px-FOV_edge])\n",
    "    plt.gca().add_patch(Rectangle((0, 0), camera_fov_px, camera_fov_px, edgecolor = 'red', fill=False))\n",
    "    plt.scatter(x,y)\n",
    "    plt.show()\n",
    "    \n",
    "    for d in range(len(str_types)):\n",
    "        imgs = sampless[d][sample_cur]\n",
    "        plt.subplot(1, 2, d%2 + 1)\n",
    "        plt.imshow(imgs[step, :, :])\n",
    "        plt.axis([-0.5, camera_fov_px-0.5, -0.5, camera_fov_px-0.5])\n",
    "        plt.scatter(x,y, c=\"red\")\n",
    "        plt.title(str_types[d])\n",
    "        \n",
    "        if (d + 1) % 2 == 0:\n",
    "            plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "interact(plot_step, step=IntSlider(min=0, max=steps - 1, layout=Layout(width='100%')), sample_cur=IntSlider(min=0, max=sample_count - 1, layout=Layout(width='100%')));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd0f69f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
